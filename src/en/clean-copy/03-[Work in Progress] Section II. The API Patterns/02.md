### [Authenticating Partners and Authorizing API Calls][api-patterns-aa]

Before we proceed further to discussing technical matters, we feel obliged to make an overview of the problems of authorizing API calls and authenticating clients that make it. Based on the very same main principle (“an API serves as a multiplier to both your opportunities and mistakes”), organizing authorization & authentication (AA) is one of the most important problems that any API vendor faces, especially if we talk about public APIs. So it's rather surprising that there is basically no standard approach to it: every big vendor develops its own interface to solve AA issues, and those interfaces are often quite archaic.

If we put aside implementation details (regarding which we once more strongly recommend not inviting a bicycle and using standard techniques and security protocols), there are basically two approaches to authorizing an API call:
  * introduce a special “robot” type of account into the system, and carry on the operations on behalf of the robot account;
  * authorize the caller system (backend or client application) as a single entity (usually API keys, signatures, or certificates are used for the purpose of authenticating such calls).

The difference between the two approaches is the access granularity:
  * if an API client is making requests as a regular user of the system, then it can conduct only the operations allowed to a specific user which in most cases implies it might have access only to a partial dataset within the API endpoint;
  * if the caller system is authorized, it implies that it has full access to the endpoint and might supply any parameters (i.e., has access to the full dataset exposed through the endpoint).

Therefore, the first approach is more granular (the robot might be a “virtual employee” and have access only to some limited dataset) and is a natural choice for those APIs that are supplemental to the existing service for end users (and thus might reuse the existing AA solutions). The disadvantages of the approach are:

  1. The necessity to develop the process of safely fetching authorization tokens for the robot user (for example, via making a real user generate tokens somewhere in the web UI) as regular login-password authentication (especially multi-factored) is poorly applicable to API clients.
  2. The necessity of to make exceptions for robot users in almost every security protocol:
    * robots might make much more requests per second than real users, and might do several queries in parallel (possibly from several different IP addresses located in different availability zones)
    * robots won't set cookies and can't solve captcha
    * robots should not be logged out or have their token invalidated “just in case” (as it means the partner's business processes will suffer), so it is usually necessary to invent specific long-living tokens for robots and/or token renew procedure.
  3. Finally, you will face big problems if it happens you *need* to allow robots to conduct operations on behalf of other users (as you will have to either expose this functionality to all users or, conversely, hide its existence from them).

If the API is not about providing additional access to some service for end users, it's usually much easier to opt-in for the second approach and authorize clients with API keys. Per-endpoint granularity might be achieved in this case (i.e., allowing partners to regulate the set of permitted endpoints for a key); developing more granular access might be much more complex and rarely see realization.

Both approaches might be morphed into one another (if we allow robot users to conduct operations on behalf of any other users, it's effectively API key-based authorization; if we allow binding some limited dataset to API key, it effectively becomes a user account), and there are some hybrid systems in the wild (the request requires to be signed with both API key and user token).

