### Наблюдаемость и строгая консистентность

Хотя в этом разделе мы стараемся говорить об API в целом, включая совершенно «классические» API языков программирования и операционных систем, нас всё же интересует вполне конкретное *семейство задач* и связанных с ними проблем. Рассматривая API как мост, связывающий два разных программных контекста, мы в большинстве случаев ожидаем, что стороны каньона функционируют независимо и изолированно друг от друга — причём чем крупнее контексты и сложнее каналы передачи данных, тем более независимо и изолированно они работают.

Что это означает на практике? Два важных следствия.

  1. Чем более распределена и многосоставна система, чем более общий канал связи используется для коммуникации — тем более вероятны ошибки в процессе взаимодействия. В частности, в наиболее интересном нам кейсе распределённых многослойных клиент-серверных систем возникновение исключения на клиенте (потеря контекста, т.е. перезапуск приложения), на сервере (конвейер выполнения запроса выбросил исключение на каком-то шаге), в канале связи (соединение полностью или частично потеряно) или любом промежуточном агенте (например, промежуточный веб-сервер не дождался ответа бэкенда и вернул ошибку гейтвея).

  2. Чем больше различных партнёров подключено к API, тем больше вероятность того, что какие-то из предусмотренных вами механизмов обеспечения корректности взаимодействия будет имплементирован неправильно. Иными словами, вы должны ожидать не только физических ошибок, связанных с состоянием сети или перегруженностью сервера, но и логических, связанных с неправильным использованием API — а в худшем случае эти ошибки ещё и могут провоцировать отказ в обслуживании других партнёров.

Представим, что конечный пользователь размещает заказ на приготовление кофе через наш API. Размещённый заказ показывается сотрудникам кофейни и, после их подтверждения, возвращается обратно.

```
// Создаёт заказ
const task = api.createOrder(…);
task.on('confirmed', (order) => {
  // С объектом order можно
  // производить дальшейшние действия
})
```

Пока этот запрос путешествует от клиента в кофейню и обратно, многое может произойти. Например, пользователь, не дождавшись результата операции, может выгрузить приложение — или оно может быть выгружено системой. Что произойдёт далее? Пользователь перезапустит приложение и, вполне логично, партнёрский код запросит текущие заказы:

```
const oders = await api
  .getOngoingOrders();
```

…и ничего не получит! Заказ ещё не подтверждён, и в списке активных отсутствует. Пользователь вполне может решить, что операция не удалась — и создать его повторно, со всеми вытекающими проблемами, весьма неприятными с продуктовой точки зрения.

Поэтому первое универсальное правило разработки API выглядит следующим образом: **клиент должен всегда иметь возможность выяснить точно текущее состояние системы**, т.е. знать, какие операции выполняются сейчас от его имени. В переданном выше примере необходимо реализовать функциональность получения висящих неподтверждённых заказов — либо обогатив функцию `getOngoingOrders`, либо, если это невозможно, через отдельный эндпойнт.

Хотя правило выше и сформулировано как универсальное, как мы понимаем, абсолютной гарантии его исполнения достичь очень сложно. Фактически, это требование — последующие чтения ресурса возвращают его состояние с учётом всех предыдущих изменений — есть требование [строгой консистентности (*strict consistency*)](https://en.wikipedia.org/wiki/Consistency_model#Strict_consistency) в отношении API.

Но, как нетрудно убедиться, одной лишь строгой консистентности нам недостаточно, чтобы избежать повторного создания заказа. Рассмотрим следующую последовательность событий.

  1. Клиент отправляет запрос на создание нового заказа.
  2. Из-за сетевых проблем запрос идёт до сервера очень долго, а клиент получает таймаут:
    * клиент, таким образом, не знает, был ли выполнен запрос или нет.
  3. Клиент запрашивает текущее состояние системы и получает пустой ответ, поскольку таймаут случился раньше, чем запрос на создание заказа дошёл до сервера:
      ```
      const pendingOrders = await 
        api.getOngoingOrders() // → []
      ```
  4. Сервер, наконец, получает запрос на создание заказа и исполняет его.
  5. Клиент, не зная об этом, создаёт заказ повторно.

Поскольку действия чтения списка актуальных заказов и создания нового заказа разнесены во времени, мы не можем гарантировать, что между этими запросами состояние системы не изменилось. Если же мы хотим такую гарантию дать, нам нужно обеспечить не только консистентность, но и какую-то из [стратегий синхронизации](https://en.wikipedia.org/wiki/Synchronization_(computer_science)). Если в случае, скажем, API операционных систем или клиентских фреймворков мы можем воспользоваться предоставляемыми платформой примитивами, то в кейсе распределённых сетевых API такой примитив нам придётся разработать самостоятельно.

Существуют два основных подхода к решению этой проблемы — пессимистичный (программная реализация блокировок) и оптимистичный (версионирование ресурсов).

##### Программные блокировки

Первый подход — очевидным образом перенести стандартные примитивы синхронизации на уровень API. Например,вот так:

```
let lock;
try {
  // Захватываем право
  // на эксклюзивное исполнение
  // операции создания заказа
  lock = await api.
    acquireLock(ORDER_CREATION);
  // Получаем текущий список
  // заказов, известных системе
  const pendingOrders = await 
    api.getPendingOrders();
  // Если нашего заказа ещё нет,
  // создаём его
  const task = await api
    .createOrder(…)
} catch (e) {
  // Обработка ошибок
} finally {
  // Разблокировка
  await lock.release();
}
```

Думаем, излишне уточнять, что подобного рода подход крайне редко реализуется в распределённых сетевых API, из-за комплекса связанных проблем.

  1. Сама по себе блокировка — это ещё одна сущность, которую каким-то образом нужно уметь строго консистентно создавать и возвращать.
  2. Поскольку клиентская часть разрабатывается сторонними партнёрами, мы не можем гарантировать, что написанный ими код корректно работает с блокировками; неизбежно в системе появятся «висящие» блокировки, а, значит, придётся предоставлять партнёрам инструменты для отслеживания и отладки возникающих проблем.
  3. Необходимо разработать достаточную гранулярность блокировок, чтобы партнёры не могли влиять на работоспособность друг друга. Хорошо, если мы можем ограничить блокировку, скажем, конкретным конечным пользователем в системе партнёра; но если этого сделать не получается (например, если система авторизации общая и все партнёры имеют доступ к одному и тому же профилю пользователя), то необходимо разрабатывать ещё более комплексные системы, которые будут исправлять потенциальные ошибки в коде партнёров — например, вводить квоты на блокировки.

##### Оптимистичное управление параллелизмом

Более щадящий вариант — это реализовать [оптимистичное управление параллелизмом](https://en.wikipedia.org/wiki/Optimistic_concurrency_control) и потребовать от клиента передавать признак того, что он располагает актуальным состоянием разделяемого ресурса.

```
// Получаем состояние
const orderState = 
  await api.getOrderState();
// Частью состояния является
// версия ресурса
const version = 
  orderState.latestVersion;
// Заказ можно создать,
// только если версия состояния
// не изменилась с момента чтения
try {
  const task = await api
    .createOrder(version, …);
} catch (e) {
  // Если версия неверна, т.е. состояние
  // было параллельно изменено
  // другим клиентом, произойдёт ошибка
  if (Type(e) == INCORRECT_VERSION) {
    // Которую нужно как-то обработать…
  }
}
```

Достоинство этого подхода — его относительная простота (если мы уже гарантируем строгую консистентность, то иметь счётчик версий не составит труда). Недостаток — необходимость в клиентском коде предусмотреть обработку ошибки несовпадения версий (которая в случае каких-то проблем на стороне клиента или сервера может потенциально привести к бесконечному циклу попыток модификации разделяемого ресурса).

**NB**: вместо версий можно использовать дату последней модификации ресурса (не забывайте сохранять её с максимально доступной точностью!) либо идентификаторы сущности (ETag).

### Слабая консистентность

Если мы можем обеспечить и сильную консистентность, и удобное управление параллелизмом — это, конечно, сделает API очень удобным для разработчика. Увы, имплементация обоих концепций сопряжена с большими техническими трудностями, главная из которых — сложность горизонтального масштабирования таких систем.

В современных микросервисных архитектурах моделью по умолчанию скорее является [слабая консистентность](https://en.wikipedia.org/wiki/Eventual_consistency) (она же «событийная консистентность», «согласованность в конечном счёте»). Если мы отражаем в API некоторый процесс реального мира — заказа кофе, в частности — то в самом деле странно пытаться добиваться большей степени целостности, чем возможна без использования API. Клиент может озвучить заказ одному бариста и, не дожидаясь подтверждения, повторить его другому бариста в соседнем заведении — получив с некоторой вероятностью два одинаковых напитка. Никто не пытается организовать для всех бариста в мире один общий гроссбух, куда они записывают заказы ради сверки, не является ли повторный заказ ошибкой — зачем же пытаться организовать такой гроссбух программно?

Рассуждение выше верное, но лукавое. Программные интерфейсы, в отличие от большинства живых бариста, обладают способностью мультиплицировать ошибки. Допустим, клиентский код написан оптимистично, без всяких моделей разрешения проблем параллелизма, и, в случае ошибки создания заказа, проверяет текущее состояние и пересоздаёт заказ, если не найдёт его. Пока система работает нормально, и время синхронизации реплик БД много меньше типичного времени сетевого таймаута и последующего перезапроса, всё работает (почти) безошибочно. Но стоит случиться проблеме синхронизации (т.е. репликам БД отстать от основного узла на значительное время), как *все* перезапросы начнут создавать новый заказ!

Если мы не можем обеспечить строгую консистентность, то мы можем хотя бы облегчить разработчику задачу написания кода — так, чтобы понизить шансы допустить критическую ошибку. Важный паттерн, который поможет в этой ситуации — это имплементация модели [«read-your-writes»](https://en.wikipedia.org/wiki/Consistency_model#Read-your-writes_consistency), а именно гарантии, что клиент всегда «видит» те изменения, которые сам же и внёс. Поднять уровень слабой консистентности до read-your-writes можно, если предложить клиенту самому передать токен, описывающий его последние изменения.

```
const order = await api.
  createOrder(…);
const pendingOrders = await api.
  getOngoingOrders({
    …,
    // Передаём идентификатор
    // последней операции
    // совершённой клиентом
    lastKnownOrderId: order.id
  })
```

В качестве такого токена может выступать, например:
  * идентификатор или идентификаторы последних модифицирующих операций, выполненных клиентом;
  * последняя известная версия ресурса, если она существует;
  * последняя известная клиенту дата модификации ресурса (если таковая получена с сервера).

Получив такой токен, сервер должен проверить, что ответ (список текущих операций, который он возвращает) соответствует токену, т.е. консистентность «в конечном счёте» сошлась. Если же она не сошлась (клиент передал дату модификации / версию / идентификатор последнего заказа новее, чем известна в данном узле сети), то сервер может реализовать одну из трёх стратегий (или их произвольную комбинацию):

  * запросить данные из нижележащего БД или другого хранилища повторно;
  * вернуть клиенту ошибку, индицирующую необходимость повторить запрос через некоторое время;
  * обратиться к основной реплике БД, если таковая имеется, либо иным образом инициировать запрос мастер-данных из хранилища.

На первый взгляд может показаться, что имплементация этой модели помогает только в случае ненадёжного канала связи или задержек репликации на сервере, но не в случае ненадёжного клиента: если приложение было перезапущено и пытается восстановить состояние, оно не располагает токеном изменений и не может гарантировать получение свежих данных. Это действительно так, но не будем забывать, что наша цель состоит всё-таки в недопущении массовых проблем.

**Во-первых**, таким подходом мы купируем автоматическое пересоздание заказа: если были утрачены токены изменений, то и сведения о последнем созданном пользователем заказе тоже скорее всего утрачены. А, значит, пользователю придётся пройти полный путь создания заказа мануально, что занимает гораздо большее время, нежели простой программный перезапрос. За это время событийная консистентность должна разрешиться, и пользователь увидит свой заказ в системе. (Если, конечно, разработчик клиентского приложения реализовал его разумно.)

**Во-вторых**, вряд ли ошибки с перезапуском приложения могут массово произойти у значительного числа клиентов. Мультипликация проблемы по сценарию, описанному в начале главы, может случиться только в случае достаточно уникального стечения обстоятельств.

**NB**: на всякий случай напомним, что выбирать подходящий подход вы можете только в случае разработки новых API. Если вы уже предоставляете эндпойнт, реализующий какую-то модель консистентности, вы не можете понизить её уровень (в частности, сменить строгую консистентность на слабую), даже если вы никогда не документировали текущее поведение явно (см. главу «О ватерлинии айсберга»). И даже замена слабой консистентности на read-your-writes мало поможет, т.к. вам придётся объяснить всем партнёрам необходимость переписать код на новую схему взаимодействия, что растянет её адаптацию на месяцы и годы.
