### Принципы организации HTTP API

Перейдём теперь к конкретике: что конкретно означает «следовать семантике протокола» и «разрабатывать приложение в соответствии с архитектурным стилем REST». Напомним, речь идёт о следующих принципах:
  * операции должны быть stateless;
  * данные должны размечаться как кэшируемые или некэшируемые;
  * интерфейсы взаимодействия между компонентами должны быть стандартизированы;
  * сетевые системы многослойны;

эти принципы мы должны применить к протоколу HTTP, соблюдая дух и букву стандарта:

  * URL операции должен идентифицировать ресурс, к которому применяется действие, и быть ключом кэширования для `GET` и ключом идемпотентности — для `PUT` и `DELETE`;
  * HTTP-глаголы должны использоваться в соответствии с их семантикой;
  * свойства операции (безопасность, кэшируемость, идемпотентность, а также симметрия `GET` / `PUT` / `DELETE`-методов), заголовки запросов и ответов, статус-коды ответов должны соответствовать спецификации.

**NB**: мы намеренно опускаем многие тонкости стандарта:
  * ключ кэширования фактически является составным [включает в себя заголовки запроса], если в ответе содержится заголовок `Vary`;
  * ключ идемпотентности также может быть составным, если в запросе содержится заголовок `Range`;
  * политика кэширования в отсутствие явных заголовков кэширования определяется не только глаголом, но и статус-кодом и другими заголовками запроса и ответа, а также политиками платформы

В рамках HTTP API использование подобных техник является скорее экзотикой, поэтому в целях сохранения размеров глав в рамках разумного касаться этих вопросов мы не будем.

Рассмотрим построение HTTP API на конкретном примере. Представим себе, например, процедуру старта приложения. Как правило, на старте требуется, используя сохранённый токен аутентификации, получить профиль текущего пользователя и важную информацию о нём (в нашем случае — текущие заказы). Мы можем достаточно очевидным образом предложить для этого эндпойнт:

```
GET /v1/state HTTP/1.1
Authorization: Bearer <token>
→
HTTP/1.1 200 Ok
Content-Type: application/json

{
  "profile",
  "orders"
}
```

Получив такой запрос, сервер проверит валидность токена, получит идентификатор пользователя `user_id`, обратится к базе данных и вернёт профиль пользователя и список его заказов.

Подобный простой API нарушает сразу несколько архитектурных принципов REST:
  * нет кэширования (и оно вряд ли возможно, так как в одном ответе совмещены разнородные данные);
  * операция является stateful, т.к. сервер не знает идентификатор клиента (к которому привязаны запрошенные данные), пока не проверит токен;
  * система однослойна (и таким образом вопрос об унифицированном интерфейсе бессмыслен).

Пока вопросы производительности нас не волнуют, подобная схема прекрасно работает. Однако, с ростом количества пользователей, мы рано или поздно столкнёмся с тем, что подобная монолитная архитектура нам слишком дорого обходится. Допустим, мы приняли решение декомпозировать единый бэкенд на четыре микросервиса:
  * сервис A, проверяющий авторизационные токены;
  * сервис B, хранящий профили пользователей;
  * сервис C, хранящий заказы пользователей;
  * сервис-гейтвей D, который маршрутизирует запросы между другими микросервисами.

Таким образом, запрос будет проходить по следующему пути:
  * гейтвей D получит запрос и отправит его в сервисы B и C;
  * сервисы B и C обратятся к сервису A, проверят токен, и вернут данные по запросу;
  * сервис D скомбинирует ответы сервисов B и C и вернёт их пользователю.

Нетрудно заметить, что мы тем самым создаём нагрузку на сервис A: теперь к нему обращается каждый из вложенных микросервисов; даже если мы откажемся от аутентификации пользователей в конечных сервисах, оставив её только в сервисе D, проблему это не решит, поскольку сервисы B и C самостоятельно выяснить идентификатор пользователя они не могут. Очевидный способ избавиться от лишних запросов — сделать так, чтобы однажды полученный `user_id` передавался остальным сервисам по цепочке:

  * гейтвей D получает запрос и через сервис A меняет токен на `user_id`
  * гейтвей D обращается к сервису B
      ```
      GET /v1/profiles
      X-OurApi-User-Id: <user id>
      ```
      и к сервису C
      ```
      GET /v1/orders
      X-OurApi-User-Id: <user id>
      ```

**NB**: альтернативно мы могли бы закодировать имя пользователя в самом токене согласно, например, [стандарту JWT](https://www.rfc-editor.org/rfc/rfc7519) — для данного кейса это неважно, поскольку `user_id` всё равно остаётся частью HTTP-заголовка.

Теперь сервисы B и C получают запрос в таком виде, что им не требуется выполнение дополнительных действий (идентификации пользователя через сервис А) для получения результата. Тем самым мы переформулировали запрос так, что он *не требует от (микро)сервиса обращаться за данными за пределами его области ответственности*, добившись соответствия stateless-принципу.

Вопрос о том, в чём разница между **stateless** и **stateful** подходами, вообще говоря, не имеет простого ответа. Микросервис B сам по себе хранит состояние клиента (профиль пользователя) и, таким образом, является stateful с точки зрения буквы диссертации Филдинга. Тем не менее, мы соглашаемся с тем, что хранить данные по профилю пользователя и только проверять валидность токена — это более правильный подход, чем хранить те же данные плюс кэш токенов, из которого можно извлечь идентификатор пользователя. Фактически, мы говорим здесь о *логическом* принципе изоляции уровней абстракции, который мы подробно обсуждали в соответствующей главе:
  * микросервисы разрабатываются так, чтобы не хранить данные, не относящиеся к другим уровням абстракции;
  * такие «внешние» данные являются лишь идентификаторами контекстов, и сам микросервис никак их не трактует;
  * если всё же какие-то дополнительные операции с внешними данными требуется производить (например, проверять, авторизована ли запрашивающая сторона на выполнение операции), то следует *организовать передачу данных так, чтобы свести операцию к проверке целостности переданных данных* (в нашем примере — использовать подписывание запросов вместо хранения копии базы данных токенов).

Пойдём теперь чуть дальше и подметим, что профиль пользователя меняется достаточно редко, и нет никакой нужды каждый раз получать его заново — мы могли бы закэшировать его на стороне гейтвея D. Для этого нам нужно сформировать ключ кэша, которым фактически является идентификатор клиента. Мы можем пойти длинным путём:
  * перед обращением в сервис B составить ключ и обратиться к кэшу;
  * если данные имеются в кэше, ответить клиенту из кэша; иначе обратиться к сервису B и сохранить полученные данные в кэш.

А можем срезать пару углов: если мы добавим идентификатор пользователя непосредственно в запрос, то можем положиться на HTTP-кэширование, которое наверняка или реализовано в нашем фреймворке, или добавляется в качестве плагина за пять минут. Тогда гейтвей D обратится к ресурсу `/v1/profiles/{user_id}` в сервисе B и получит данные либо из кэша, либо непосредственно из сервиса.

Теперь рассмотрим сервис C. Результат его работы мы тоже могли бы кэшировать, однако состояние текущего заказа меняется гораздо чаще, чем список завершённых заказов. Вспомним, однако, описанное нами в разделе «Паттерны API» оптимистичное управление параллелизмом: для корректной работы сервиса нам нужна ревизия состояния ресурса, и ничто не мешает нам воспользоваться этой ревизией как ключом кэша. Пусть сервис С возвращает нам токен, соответствующий текущему состоянию заказов пользователя:

```
GET /v1/orders?user_id=<user_id> HTTP/1.1
→
HTTP/1.1 200 Ok
ETag: <ревизия>
…
```

И тогда гейтвей D при выполнении запроса может:

  1. Закэшировать результат выполнения `GET /v1/orders?user_id=<user_id>`, использовав URL как ключ кэша
  2. При получении повторного запроса:
      * найти закэшированное состояние, если оно есть
      * отправить запрос к сервису B вида
          ```
          GET /v1/orders?user_id=<user_id> HTTP/1.1
          If-None-Match: <ревизия>
          ```
      * если сервис B отвечает статусом 304 Not Modified, вернуть данные из кэша
      * если сервис B отвечает новой версией данных, сохранить её в кэш и вернуть

**NB**: мы использовали нотацию `/v1/orders?user_id`, а не, допустим, `/v1/users/{user_id}/orders` по двум причинам:
  * сервис текущих заказов хранит заказы, а не пользователи — логично если URL будет это отражать;
  * если нам потребуется в будущем позволить нескольким пользователям делать общий заказ, нотация `/v1/orders?user_id` будет лучше отражать отношения между сущностями (напомним, путь традиционно используется для индикации строгой иерархии).

Подчеркнём ещё раз: стандарт не определяет, каким образом формируются URL — как разбивать путь на части (и разбивать ли вообще), в каких случаях передавать параметр в query, а в каких в path и т.д. — поэтому path и query формируются сугубо из удобства чтения и использования. Если представить, что гейтвей D реализован в виде stateless прокси с декларативной конфигурацией, то было бы гораздо удобнее получать от клиента запрос в виде:
  * `GET /v1/state?user_id=<user_id>`
и преобразовывать в пару вложенных запросов
  * `GET /v1/profiles?user_id=<user_id>`
  * `GET /v1/ongoing-orders?user_id=<user_id>`
поскольку эту операцию [замена одного path целиком на другой] достаточно описать в конфигурации, и в большинстве ПО для веб-серверов она поддерживается из коробки. Напротив, извлечение данных из разных частей запроса и полная пересборка URL — достаточно сложная функциональность, которая, скорее всего, потребует от гейтвея поддержки скриптового языка программирования и/или написания специального модуля для таких манипуляций. Аналогично, автоматическое построение мониторинговых панелей в популярных сервисах типа связки Prometheus+Grafana гораздо проще организовать по path, чем вычленять из данных запроса какой-то синтетический ключ группировки запросов.

Таким образом, мы не настаиваем на этом решении [организации доступа к заказам пользователя через манипуляцию path в URL с передачей идентификатора пользователя в виде query-параметра] как на единственно верном, хотя он в большинстве случаев упрощает и организацию гейтвеев и мониторингов: в первую очередь нам важно, чтобы URL был ключом кэширования и идемпотентности, а для этого подходит любой формат, лишь бы он задавал однозначное соответствие URL списку заказов конкретного пользователя.

Использовав такое решение [с формированием URL как ключа кэширования и идемпотентности], мы автоматически получаем ещё один приятный бонус: эти же данные пригодятся нам, если пользователь попытается создать новый заказ. Допустим, пользователь выполняет запрос вида:

```
POST /v1/orders HTTP/1.1
If-Match: <ревизия>
```

Гейтвей D подставляет в запрос идентификатор пользователя и формирует запрос к сервису B:

```
POST /v1/orders?user_id=<user_id> HTTP/1.1
If-Match: <ревизия>
```

Если ревизия правильная, гейтвей D может сразу же получить в ответе сервиса B:

```
HTTP/1.1 200 OK
Content-Location: /v1/orders?user_id<user_id>
ETag: <новая ревизия>

{ /* обновлённый список текущих заказов */ }
```

и обновить кэш в соответствии с новыми данными.

**Важно**: обратите внимание на то, что, после всех преобразований, мы получили систему, в которой мы можем *убрать гейтвей D* и возложить его функции непосредственно на клиентский код. В самом деле, ничто не мешает клиенту:
  * хранить на своей стороне `user_id` (либо извлекать его из токена, если формат позволяет) и последний полученный ETag состояния списка заказов;
  * вместо одного запроса `GET /v1/state` сделать два запроса (`GET /v1/profiles/{user_id}` и `GET /v1/orders?user_id=<user_id>`), благо протокол HTTP/2 поддерживает мультиплексирование запросов по одному соединению;
  * поддерживать на своей стороне кэширование результатов обоих запросов.

С точки зрения реализации сервисов B и C наличие или отсутствие гейтвея перед ними ни на что не влияет (особенно если мы используем stateless-токены). Мы также можем добавить и второй гейтвей в цепочку, если, скажем, мы захотим разделить хранение заказов на «горячее» и «холодное» хранилища.

Если мы теперь обратимся к началу главы, мы обнаружим, что мы построили систему, полностью соответствующую требованиям REST:
  * запросы к сервисам уже несут в себе все данные, которые необходимы для выполнения запроса;
  * интерфейс взаимодействия настолько унифицирован, что мы можем передавать функции гейтвея клиенту и обратно;
  * политика кэширования каждого вида данных размечена.

Важнейшее качество, которое следование семантике HTTP придаёт нашему сервису — это унификация кода различных агентов системы. Клиент и гейтвей почти полностью идентичны и взаимозаменяемы, что позволяет понятным и предсказуемым образом наращивать номенклатуру сервисов и горизонтально, и вертикально.

**NB**: повторимся, что мы можем добиться того же самого, использовав RPC-протоколы или разработав свой формат описания статуса операции, параметров кэширования, версионирования ресурсов, приписывания и чтения метаданных и параметров операции, а также реализовав гейтвей D поверх RPC-протокола с чтением полного тела запросов и ответов и интерпретацией всех придуманных нами (или вендором RPC-протокола) форматов данных. Но автор этой книги позволит себе, во-первых, высказать некоторые сомнения в качестве получившегося решения, и, во-вторых, отметить огромное количество кода, которое придётся написать для реализации всего вышеперечисленного.